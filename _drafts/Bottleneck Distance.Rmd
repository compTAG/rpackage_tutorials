---
layout: post
title: "Bottleneck Distance"
author: "Ben Holmgren"
date: "October 20, 2019"
---


## Introduction

By this point, you should have some familiarity with the concept of a filtration in TDA, and how we can describe the findings of a filtration through a [persistence diagram](https://comptag.github.io/rpackage_tutorials/2019/04/persistent_homology.html). If you are unfamiliar or would like to review the concept of a filtration, a tutorial on Rips filtrations can be found at <https://comptag.github.io/rpackage_tutorials/2019/07/tda-rips-tutorial.html>. For a review of persistence diagrams, take a look at our tutorial at <https://comptag.github.io/rpackage_tutorials/2019/04/persistent_homology.html>.

---

## Objectives
* Define bottleneck distance
* Conceptualize the implications of a bottleneck distance on the topological similarity of point cloud data
* Be able to roughly compute a bottleneck distance by hand
* Gain an idea of some applications of the bottleneck distance
* Compute a bottleneck distance using **bottleneck** function in the TDA Package

---

## Definition
Conceptually, we can view bottleneck distance as the distance between two persistence diagrams. 

Formally, the bottleneck distance takes as an input two persistence diagrams, G and H, and considers bijections *n* : G &rarr; H and records the infimum of the supremum between each. What does this mean? Consider the following two persistence diagrams. We can see that they don't actually look all that different from one another.

```{r pds, echo=FALSE, out.width = '80%'}
par(mfrow=c(1,2))
par(pty="s")
plot(0:10, 0:10, main = "G", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)
lines(0:10, 0:10)

for (i in 1:6) {
  points(x[i], y[i], pch=15)
}
par(pty="s")
plot(0:10, 0:10, main = "H", xlab = "", ylab = "", type = "n")
a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)
lines(0:10, 0:10)

for(i in 1:7){
  points(a[i], b[i], pch=20)
}

```

Now envision what would happen if we layered G and H on top of each other. We'd gain a combined persistence diagram that looked something like this:

```{r points, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)


for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```




We can see that G, which is illustrated b circular points on the persistence diagram, and H, which is illustrated by squares, have points which are logical to pair together. This is where we find a bijection, and can compare points based on their position respective to a corresponding point on another persistence diagram.

---

Algorithmically, the bottleneck distance is found by iteratively pairing vertices, and recording the pair with the largest distance in each iteration. For example, using the above example:

```{r pairs, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)
segments(.5,3,2,9, col = "purple")
segments(2.75,5.75,1,4, col = "purple")
segments(2,8.5,3,5, col = "purple")
segments(3,10,2.75,10, col = "purple")

#it1dist <- 1.75

#rect((a[2] - it1dist), (b[2] - it1dist), (a[2] + it1dist), (b[2] + it1dist))

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```


Our pairing looks great, but you may have noticed that not every vertex has a corresponding vertex to pair with.
```{r matchDiag, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)
segments(.5,3,2,9, col = "purple")
segments(2.75,5.75,1,4, col = "purple")
segments(2,8.5,3,5, col = "purple")
segments(3,10,2.75,10, col = "purple")

#it1dist <- 1.75

rect((5), (5), (6.5), (6.5))

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```

In the case of a mismatch, unpaired vertices are paired to the diagonal, and this distance is considered just as any other pairing. It is also important to note that the pairing takes place along a direct diagonal path to the persistence diagram's diagonal, as follows:
```{r matchDiag2, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)
segments(.5,3,2,9, col = "purple")
segments(2.75,5.75,1,4, col = "purple")
segments(5.5,6,5.75,5.75, col = "purple")
segments(2,8.5,3,5, col = "purple")
segments(3,10,2.75,10, col = "purple")

#it1dist <- 1.75

rect((5), (5), (6.5), (6.5))

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```

With this pairing, we can probably make out the shortest distance as the distance which we mark here by a rectangle. The distance is recorded by its largest difference in one dimension, but coincidently here the axes are equivalent, so either value can be chosen. You'll also notice that we don't quite have an exact matchup in the number of vertices, so any vertex which is left over is paired to the diagonal and it's distance is recorded as any other pairing.

```{r rectpairs, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)
segments(.5,3,2,9, col = "purple")
segments(2.75,5.75,1,4, col = "purple")
segments(5.5,6,5.75,5.75, col = "purple")
segments(2,8.5,3,5, col = "purple")
segments(3,10,2.75,10, col = "purple")

rect(a[1], b[1], (x[3]), (y[3]))

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```

We can also probably tell that we could choose better pairings that would yield shorter distances. Let's try again, marking new pairings in red, and recording the largest distance that we find for this iteration:

```{r rect2pairs, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)
segments(.5,3,1,4, col = "red")
segments(2.75,5.75,2,9,col = "red")
segments(2.75,10,3,10,col = "red")
segments(2,8.5,3,5,col = "red")
segments(5.75,5.75,5.5,6,col = "red")

rect(a[4],b[4],x[2],y[2])

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```

This time, we find a few "good" pairs, whose partners are actually the closest corresponding vertex.

Eventually, if we carry on this process and mark every possible pairing, we will have a complete set of longest matches. Considering all of the longest matches, our bottleneck distance is the shortest distance in this set. In other words, our bottleneck distance ends up being the largest distance in the "ideal" pairing, where each vertex is matched to its closest neighbor.

---

I know that's a bit of a mouthful. To visualize, the bottleneck distance between persistence diagrams G and H can be seen as the "y" dimension of the marked green rectangle, which links the pair of vertices which fit all of our criteria. 

```{r bottledpoints, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)

rect(.5,3,1,4,col = "green")

for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
}
```

---

For a larger scale visualization, this will be the image of persistence diagrams G and H if we include squares with sidelengths which are twice the bottleneck distance to show the reach of the bottleneck distance from points.

```{r rect_pts, echo=FALSE}
par(pty="s")
plot(0:10, 0:10, main = "Combined G H", xlab = "", ylab = "", type = "n")
x <- c(1,3,2,3)
y <- c(4,5,9,10)

a <- c(.5,2.75,5.5,2,2.75)
b <- c(3,5.75,6,8.5,10)

lines(0:10, 0:10)

#compute bottleneck dist in this context
bottleDist <- sqrt((.5 - 1)^2 + (3 - 4)^2)


for(i in 1:7){
  points(a[i], b[i], pch=20)
  points(x[i], y[i], pch=15)
  rect((a[i] - bottleDist), (b[i] - bottleDist), (a[i] + bottleDist), (b[i] + bottleDist))
}
```



Now we can visualize G and H combined so that the squares surrounding points from H have sidelength of 2 * bottleneck distance. This can serve as a visual description of where vertex pairs must lie, and may help visualize the actual definition of the bottleneck distance.

---

## Meaning of the Bottleneck Distance

The bottleneck distance clearly provides a decent description of the similarity of two persistence diagrams. But what does this actually tell us about the topology of two different data sets?

It turns out, quite a lot!

The power of the bottleneck distance lies in its significance to the stability theorem. We won't get into that here, but essentially the meaning of the stability theorem suggests that bottleneck distances will correspond adequately to differences in persistence diagrams, which tells us in one simple value whether or not the structure of two data sets is reasonably similar, or overwhelmingly different.

This is actually a very meaningful tool, because we can gain a value which tells us to some degree whether or not we can consider two data sets structurally similar. 

---

## Examples

For example, consider the two relatively similar data sets, *Nice Cycle* and *Angsty Cycle*:

```{r plot_good_circle, message=FALSE, echo=FALSE}
library('TDA')
library('spatstat')
par(pty="s")
x <- circleUnif(100,1.5)
Nice_Cycle <- as.ppp.data.frame(x,c(-2,2,-2,2))
plot(Nice_Cycle, pch = 18, xlab = "", ylab = "")

xppp <- as.ppp.data.frame(Nice_Cycle,c(-2,2,-2,2))
Angsty_Cycle <-rjitter(xppp,0.25)
plot(Angsty_Cycle, pch = 16, xlab = "", ylab = "")
```


We should have similar persistence diagrams for each data set under a rips filtration:
```{r persists1, echo=FALSE}
 r1 <- ripsDiag(x,2,1)
 # change x2 to data frame to use in ripsdiag
 x2frame <- as.data.frame(Angsty_Cycle)
 r2 <- ripsDiag(x2frame,2,1)

 par(mfrow=c(1,2))
 par(pty="s")
 plot(r1[["diagram"]], main = "Nice Cycle")
 plot(r2[["diagram"]], main = "Angsty Cycle")
 
```

Now we can use the **bottleneck** function to compute the bottleneck distance as:

 ```{r bottle_stuff, echo=FALSE}
 b <- bottleneck(r1[["diagram"]],r2[["diagram"]], dimension=0)
 b
```

We find a relatively small value, which tells us that our persistence diagrams really aren't all that different, and in turn tells us that our underlying data has a similar structure.

---

For a counterexample, consider again our dataset *Nice Cycle*, and a completely different dataset *Nice Cycle And a Buddy*:

```{r plot_dos_circles, message=FALSE, echo=FALSE}
plot(Nice_Cycle, pch = 18, xlab = "", ylab = "")
x <- circleUnif(100,0.75)
newcirc <- x[, 1] + .75
topcirc <- cbind(newcirc,x[,2])
newcirc2 <- x[,1] -.75
bottomcirc <- cbind((newcirc2),x[,2])

magiceight <- rbind(bottomcirc,topcirc)
Nice_Cycle_and_a_Buddy <- as.ppp.data.frame(magiceight,c(-2,2,-2,2))

plot(Nice_Cycle_and_a_Buddy, pch = 20, xlab = "", ylab = "")
```

Conducting a Rips filtration on both point clouds, we find the persistence diagrams:

```{r persists2, echo=FALSE}
 r3 <- ripsDiag(magiceight,2,1)

 par(mfrow=c(1,2))
 par(pty="s")
 plot(r1[["diagram"]], main = "Nice Cycle")
 plot(r3[["diagram"]], main = "Nice Cycle and a Buddy")
 
```

And then using these persistence diagrams, we can compute the bottleneck distance to be: 

 ```{r bottle_more_stuff, echo=FALSE}
 b <- bottleneck(r1[["diagram"]],r3[["diagram"]], dimension=0)
 b
```
Roughly twice that of the distance between *Nice Cycle* and *Angsty Cycle*. Which tells us that *Nice Cycle* and *Nice Cycle and a Buddy* are significantly less similar and *Nice Cycle* and *Angsty Cycle*, as we would expect!(Since the dataset *Nice Cycle and a Buddy* has one more cycle).
As a result, we see that the bottleneck distance can be a robust mechanism to show the wholistic similarity of data in one concrete value!

---
## Now, try a simple example

Using the following R code as a template, you should be able to compute the bottleneck distance on your own data and gain a numerical, wholistic descriptor of the difference in datasets:

```{r we_persist}
# generate 50 points along the unit circle (because topologists are really into circles)
a <- circleUnif(50)

# generate 55 points along a slightly smaller circle (because topologists are reeeaaaally into circles)
b <- circleUnif(55, r = 0.80)

# compute a rips filtration on a
aDiag <- ripsDiag(a,2,1)

# compute a rips filtration on b
bDiag <- ripsDiag(b,2,1)

# plot your diagrams to visualize
par(mfrow=c(1,2))
par(pty="s")
plot(aDiag[["diagram"]], main = "a")
plot(bDiag[["diagram"]], main = "b")

# compute bottleneck distance between a and b
bottleneck_dist_ab <- bottleneck(aDiag[["diagram"]], bDiag[["diagram"]], dimension=0)
 
# check out your findings!
bottleneck_dist_ab
 
```


## Why is this useful?

The bottleneck distance is extremely powerful because it allows us to see the overall similarity or difference between the structure of data sets, which may be arbitrarily large or complex. In any field which makes use of point-cloud data, it is pertinent to be able to process data in a wholistic way. In the wider world beyond this tutorial, hopefully you are able to take away a new technique that you can utilize to better comprehend data which may be complicated, and to compare your own results.

For more information on the bottleneck distance and it's uses, feel free to check out some papers which directly pertain to the bottleneck distance and its applications:

Recent algorithm which increases the efficiency of computation when comparing persistence diagrams:
<http://www.geometrie.tugraz.at/kerber/kerber_papers/kmn-ghtcpd-16.pdf>

//TODO: Find more .....

















